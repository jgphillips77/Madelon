{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter Notebook, Step 2 - Identify Features\n",
    "- Build feature selection pipelines using at least three different techniques\n",
    "- **NOTE**: these pipelines are being used for feature selection not prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Project_03_on_AWS\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start with reading the data from the pickle\n",
    "train_data = pd.read_pickle('data/train_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to Separate X, y to build models\n",
    "\n",
    "X = train_data.drop('Label', axis=1)\n",
    "y = train_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-test split the our data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split some data...\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Build some Pipelines for Feature Selection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll start with LR, DTC, and KNN\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVR\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso #, Ridge\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, RFE, f_regression, chi2, f_classif\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make first Pipeline with the train_data.\n",
    "\n",
    "train_data_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(C=100)),\n",
    "    ('dectre', DecisionTreeClassifier()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=17)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logreg', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear'...wski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.79\n",
      "Test set score: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# What are the train and test r2 scores?\n",
    "print(\"Training set score: {:.2f}\".format(train_data_pipeline.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(train_data_pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is best score so far with roughly 83% Train and 80% Test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a Pipeline with SVC\n",
    "data_pipeline_svc = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(C=10)),\n",
    "    ('dectre', DecisionTreeClassifier()),\n",
    "    ('svc', svm.SVC(C=10))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logreg', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear',...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pipeline_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.99\n",
      "Test set score: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# What about those train & test r2 scores?\n",
    "print(\"Training set score: {:.2f}\".format(data_pipeline_svc.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(data_pipeline_svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a train set score of 99%, this is over fit...\n",
    "\n",
    "Not performing as good at the first pipeline... hmm..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of warnings! Everybody gets a warning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More pipelines for experiments.\n",
    "\n",
    "For references of these experiements, I'm using this lovely diagram: http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "And also 'Into to Machine Learning with Python' by Müller & Guido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Experiment Pipeline3\n",
    "train_data_pipeline3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression()),\n",
    "    ('linear_svc', svm.LinearSVC(C=10)),\n",
    "    ('svc', svm.SVC(C=10))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear'...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pipeline3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.00\n",
      "Test set score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# What are the train and test r2 scores?\n",
    "print(\"Training set score: {:.2f}\".format(train_data_pipeline3.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(train_data_pipeline3.score(X_test, y_test)))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Another experiment with RandomForestClassifier\n",
    "\n",
    "train_data_pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression()),\n",
    "    ('rfc', RandomForestClassifier()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear'...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pipeline_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.99\n",
      "Test set score: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# What are the train and test r2 scores?\n",
    "print(\"Training set score: {:.2f}\".format(train_data_pipeline_rf.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(train_data_pipeline_rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, this has the best test score so far!\n",
    "But is it really overfit on the Train data?\n",
    "And I didn't even tune the hyperparameters of RFC yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Time to get some features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's split some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = train_data.sample(frac=0.1, replace=False)\n",
    "data2 = train_data.sample(frac=0.1, replace=False)\n",
    "data3 = train_data.sample(frac=0.1, replace=False)\n",
    "\n",
    "X_1 = data1.drop('Label', axis=1)\n",
    "X_2 = data2.drop('Label', axis=1)\n",
    "X_3 = data3.drop('Label', axis=1)\n",
    "\n",
    "y_1 = data1['Label']\n",
    "y_2 = data2['Label']\n",
    "y_3 = data3['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y_1, random_state = 42)\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, random_state = 42)\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3, y_3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try Recursive Feature Elimination with Logistic Regression to find some features\n",
    "rfe1 = RFE(LogisticRegression(C=10), n_features_to_select=9, step=10, verbose=0)\n",
    "scaler = StandardScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X_1_train)\n",
    "X1_test_scaled = scaler.transform(X_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfe2 = RFE(LogisticRegression(C=10), n_features_to_select=9, step=10, verbose=0)\n",
    "scaler = StandardScaler()\n",
    "X2_train_scaled = scaler.fit_transform(X_2_train)\n",
    "X2_test_scaled = scaler.transform(X_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfe3 = RFE(LogisticRegression(C=10), n_features_to_select=9, step=10, verbose=0)\n",
    "scaler = StandardScaler()\n",
    "X3_train_scaled = scaler.fit_transform(X_3_train)\n",
    "X3_test_scaled = scaler.transform(X_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "  n_features_to_select=9, step=10, verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe1.fit(X1_train_scaled, y_1_train)\n",
    "rfe2.fit(X2_train_scaled, y_2_train)\n",
    "rfe3.fit(X3_train_scaled, y_3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features are : [  2 188 209 264 328 375 377 398 452]\n",
      "The features are : [ 10  65 181 232 240 304 309 466 475]\n",
      "The features are : [ 40 226 229 241 248 304 388 439 444]\n"
     ]
    }
   ],
   "source": [
    "# Print the features.  These are different from when I ran this for the entire dataset.\n",
    "rfe1_feats = np.where(rfe1.get_support())[0]\n",
    "print(\"The features are :\", rfe1_feats)\n",
    "\n",
    "rfe2_feats = np.where(rfe2.get_support())[0]\n",
    "print(\"The features are :\", rfe2_feats)\n",
    "\n",
    "rfe3_feats = np.where(rfe3.get_support())[0]\n",
    "print(\"The features are :\", rfe3_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RFE score is : 0.72\n",
      "The RFE score is : 0.79\n",
      "The RFE score is : 0.77\n"
     ]
    }
   ],
   "source": [
    "print(\"The RFE score is : {:.2f}\".format(rfe1.score(X1_train_scaled, y_1_train)))\n",
    "print(\"The RFE score is : {:.2f}\".format(rfe2.score(X2_train_scaled, y_2_train)))\n",
    "print(\"The RFE score is : {:.2f}\".format(rfe3.score(X3_train_scaled, y_3_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Select K Best to get features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build SKB two ways, one with f_classif score function, another with chi2 score function.\n",
    "\n",
    "# Here I am working with the entire data set rather than samples\n",
    "skb_FC = SelectKBest(f_classif, k=13)\n",
    "skb_CH = SelectKBest(chi2, k=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=13, score_func=<function chi2 at 0x7f378b047d08>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb_FC.fit(X_train, y_train)\n",
    "skb_CH.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[475 241 336  64  48 105 128 378 338]\n",
      "[475 336 105  64 493 241 453 338 442]\n"
     ]
    }
   ],
   "source": [
    "# Print top 15 Features for each score function using .argsort().\n",
    "print(skb_FC.pvalues_.argsort()[:9])\n",
    "print(skb_CH.pvalues_.argsort()[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_classif</th>\n",
       "      <th>chi2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>475</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>336</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>378</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>338</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_classif  chi2\n",
       "0        475   475\n",
       "1        241   336\n",
       "2        336   105\n",
       "3         64    64\n",
       "4         48   493\n",
       "5        105   241\n",
       "6        128   453\n",
       "7        378   338\n",
       "8        338   442"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put those results in a DF.\n",
    "pd.DataFrame([skb_FC.pvalues_.argsort()[:9], skb_CH.pvalues_.argsort()[:9]], \n",
    "             index=['f_classif','chi2']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top 9 features.  This gave me the most consistent output so far.  We are looking for the top 5 features, but I wanted to include just beyond the top 5 since each method gave slightly different output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternate Pipeline to transform the data to only important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer_pipe = make_pipeline(SelectKBest(score_func=f_regression, k=9),\n",
    "                                 StandardScaler(),\n",
    "                                SelectFromModel(Lasso(), threshold='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selectkbest', SelectKBest(k=9, score_func=<function f_regression at 0x7f378b047d90>)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('selectfrommodel', SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "        prefit=False, threshold='mean'))])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "features_skb_scaled_sfm = transformer_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 9)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_skb_scaled_sfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use .get_support to get the features\n",
    "skb_support = transformer_pipe.named_steps['selectkbest'].get_support()\n",
    "sfm_support = transformer_pipe.named_steps['selectfrommodel'].get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([48, 64, 105, 128, 241, 336, 338, 378, 475], dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the columns with the features:\n",
    "X_train.columns[skb_support][sfm_support]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's Do Gridsearch with KNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knc_params = {\n",
    "    'n_neighbors': range(3,19,2)\n",
    "}\n",
    "knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid= knc_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': range(3, 19, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc_gs.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(knc_gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014749</td>\n",
       "      <td>0.321094</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.655501</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601329</td>\n",
       "      <td>0.659716</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.660833</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.591973</td>\n",
       "      <td>0.656120</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.005297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.319898</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.666668</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588040</td>\n",
       "      <td>0.671393</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.571906</td>\n",
       "      <td>0.665279</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.008905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.319776</td>\n",
       "      <td>0.572667</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.689741</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.700833</td>\n",
       "      <td>0.531773</td>\n",
       "      <td>0.690258</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.008375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014596</td>\n",
       "      <td>0.319997</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.650170</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.594684</td>\n",
       "      <td>0.661384</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.651667</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.650833</td>\n",
       "      <td>0.568562</td>\n",
       "      <td>0.641965</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.025863</td>\n",
       "      <td>0.006671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015272</td>\n",
       "      <td>0.323704</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.646167</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.588040</td>\n",
       "      <td>0.645538</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.655833</td>\n",
       "      <td>0.558528</td>\n",
       "      <td>0.645296</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.005120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015104</td>\n",
       "      <td>0.323192</td>\n",
       "      <td>0.567333</td>\n",
       "      <td>0.681333</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.685571</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.685833</td>\n",
       "      <td>0.545151</td>\n",
       "      <td>0.688593</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>0.013350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014914</td>\n",
       "      <td>0.315133</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.779330</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.594684</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.780833</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.508361</td>\n",
       "      <td>0.789342</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.034629</td>\n",
       "      <td>0.006175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014889</td>\n",
       "      <td>0.319736</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.716165</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.601329</td>\n",
       "      <td>0.716430</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.715833</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.710833</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.728560</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "5       0.014749         0.321094         0.582667          0.655501   \n",
       "4       0.014924         0.319898         0.578667          0.666668   \n",
       "2       0.014798         0.319776         0.572667          0.693500   \n",
       "6       0.014596         0.319997         0.570667          0.650170   \n",
       "7       0.015272         0.323704         0.568000          0.646167   \n",
       "3       0.015104         0.323192         0.567333          0.681333   \n",
       "0       0.014914         0.315133         0.562667          0.779330   \n",
       "1       0.014889         0.319736         0.556000          0.716165   \n",
       "\n",
       "  param_n_neighbors               params  rank_test_score  split0_test_score  \\\n",
       "5                13  {'n_neighbors': 13}                1           0.601329   \n",
       "4                11  {'n_neighbors': 11}                2           0.588040   \n",
       "2                 7   {'n_neighbors': 7}                3           0.581395   \n",
       "6                15  {'n_neighbors': 15}                4           0.594684   \n",
       "7                17  {'n_neighbors': 17}                5           0.588040   \n",
       "3                 9   {'n_neighbors': 9}                6           0.581395   \n",
       "0                 3   {'n_neighbors': 3}                7           0.594684   \n",
       "1                 5   {'n_neighbors': 5}                8           0.601329   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "5            0.659716           0.573333       ...                  0.580000   \n",
       "4            0.671393           0.583333       ...                  0.580000   \n",
       "2            0.689741           0.580000       ...                  0.550000   \n",
       "6            0.661384           0.593333       ...                  0.573333   \n",
       "7            0.645538           0.580000       ...                  0.573333   \n",
       "3            0.685571           0.580000       ...                  0.573333   \n",
       "0            0.770642           0.543333       ...                  0.563333   \n",
       "1            0.716430           0.543333       ...                  0.533333   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "5            0.660833           0.566667            0.655000   \n",
       "4            0.675000           0.570000            0.671667   \n",
       "2            0.705000           0.620000            0.700833   \n",
       "6            0.651667           0.523333            0.650833   \n",
       "7            0.643333           0.540000            0.655833   \n",
       "3            0.691667           0.556667            0.685833   \n",
       "0            0.780833           0.603333            0.775833   \n",
       "1            0.715833           0.580000            0.710833   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "5           0.591973            0.656120      0.000117        0.003648   \n",
       "4           0.571906            0.665279      0.000553        0.003922   \n",
       "2           0.531773            0.690258      0.000343        0.002710   \n",
       "6           0.568562            0.641965      0.000200        0.005528   \n",
       "7           0.558528            0.645296      0.000598        0.005130   \n",
       "3           0.545151            0.688593      0.000547        0.002091   \n",
       "0           0.508361            0.789342      0.000791        0.005585   \n",
       "1           0.521739            0.728560      0.000542        0.006484   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "5        0.012538         0.005297  \n",
       "4        0.006817         0.008905  \n",
       "2        0.030170         0.008375  \n",
       "6        0.025863         0.006671  \n",
       "7        0.017022         0.005120  \n",
       "3        0.014135         0.013350  \n",
       "0        0.034629         0.006175  \n",
       "1        0.029939         0.006800  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.sort_values('mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 13}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really interesting results.  13 scores the best, but not a huge difference in the scores (ie: just 1% difference in score for 7 neighbors).  Interesting that 7 neighbors scores above 15, 17, and 9 neighbors.  Also 3 scores above 5 neighbors!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
